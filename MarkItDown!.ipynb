{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3hQwBY+QwuqgAqa8VWLEG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/COOLSTORM36/InvoiceExtractor/blob/main/MarkItDown!.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Prerequisite"
      ],
      "metadata": {
        "id": "lHZ2L8QmSwkA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NucIEiLr2MNO",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install markitdown langchain-community langchain langchain_openai openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from markitdown import MarkItDown\n",
        "import openai\n",
        "from google.colab import userdata\n",
        "from langchain import LLMChain\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
        "\n",
        "openai_api = userdata.get('OPENAI_API_KEY')\n",
        "openai.api_key = openai_api\n",
        "\n",
        "client = openai\n",
        "md = MarkItDown(llm_client=client, llm_model=\"gpt-4o\")"
      ],
      "metadata": {
        "id": "uwW5tesU2iKW",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MarkItDown Initialize"
      ],
      "metadata": {
        "id": "FQNisRwiUIH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def md_convert(file_path):\n",
        "    try:\n",
        "        mdresult = md.convert(file_path)\n",
        "        # print(mdresult.text_content)\n",
        "        return mdresult.text_content\n",
        "    except Exception:\n",
        "        print(f\"An error occurred:\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "uEqYUH2WUHnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parse invoice method"
      ],
      "metadata": {
        "id": "OxCHCyIITw5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_invoice(text):\n",
        "    # Create an instance of InvoiceSchema to get format instructions\n",
        "\n",
        "    # Step 1: Define the response schema\n",
        "    response_schemas = [\n",
        "        ResponseSchema(name=\"Invoice Number\", description=\"The unique number of the invoice.\"),\n",
        "        ResponseSchema(name=\"Date\", description=\"The date when the invoice was issued.\"),\n",
        "        ResponseSchema(name=\"Total Amount\", description=\"The total amount listed on the invoice.\"),\n",
        "        ResponseSchema(name=\"Vendor Name\", description=\"The name of the vendor who issued the invoice.\")\n",
        "    ]\n",
        "\n",
        "    # Step 2: Create a StructuredOutputParser\n",
        "    output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
        "\n",
        "    # Step 3: Generate format instructions for the prompt\n",
        "    format_instructions = output_parser.get_format_instructions()\n",
        "\n",
        "    # Create a prompt template for parsing invoices\n",
        "    prompt_template = PromptTemplate(\n",
        "        input_variables=[\"invoice_text\", \"format_instructions\"],\n",
        "        template=(\n",
        "            \"Extract the following information from the invoice text below and return it in JSON format, if the info is missing, leave as blank:\\n\"\n",
        "            \"{format_instructions}\\n\\n\"\n",
        "            \"Invoice Text:\\n{invoice_text}\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Create an LLM chain with the prompt template and parser\n",
        "\n",
        "    chain = LLMChain(\n",
        "        llm=ChatOpenAI(openai_api_key=openai_api, temperature=0, model_name=\"gpt-4o\"),\n",
        "        prompt=prompt_template,\n",
        "        output_parser=output_parser,\n",
        "    )\n",
        "\n",
        "    # Run the chain with the invoice text and format instructions\n",
        "    result = chain.run(invoice_text=text, format_instructions=format_instructions)\n",
        "    return result"
      ],
      "metadata": {
        "id": "05uzjbQjTwLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = \"\"\n",
        "parsed_data = parse_invoice(md_convert(filepath))\n",
        "print(parsed_data)"
      ],
      "metadata": {
        "id": "6Cpn0llEYKFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parsed_data"
      ],
      "metadata": {
        "id": "pxrBqgQWxrxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parsed_data.get('Total Amount')"
      ],
      "metadata": {
        "id": "fqfHMsRjxVoS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}